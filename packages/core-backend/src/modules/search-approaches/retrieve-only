class RetrieveOnly extends Approach {
  systemChatTemplate = "You are an intelligent assistant helping Contoso Inc employees with their healthcare plan questions and employee handbook questions. "
      + "Use 'you' to refer to the individual asking the questions even if they ask with 'I'. "
      + "Answer the following question using only the data provided in the sources below. "
      + "For tabular information return it as an html table. Do not return markdown format. "
      + "Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. "
      + "If you cannot answer using the sources below, say you don't know. Use below example to answer";

  question = "'What is the deductible for the employee plan for a visit to Overlake in Bellevue?'"
      + "\n\nSources:"
      + "\ninfo1.txt: deductibles depend on whether you are in-network or out-of-network. In-network deductibles are $500 for employee and $1000 for family. Out-of-network deductibles are $1000 for employee and $2000 for family."
      + "\ninfo2.pdf: Overlake is in-network for the employee plan."
      + "\ninfo3.pdf: Overlake is the name of the area that includes a park and ride near Bellevue."
      + "\ninfo4.pdf: In-network institutions include Overlake, Swedish and others in the region";

  answer = "In-network deductibles are $500 for employee and $1000 for family [info1.txt] and Overlake is in-network for the employee plan [info2.pdf][info4.pdf].";

  searchClient: SearchClient;
  chatgptDeployment: string | null;
  openaiClient: AsyncOpenAI;
  authHelper: AuthenticationHelper;
  chatgptModel: string;
  embeddingModel: string;
  embeddingDeployment: string | null;
  sourcepageField: string;
  contentField: string;
  queryLanguage: string;
  querySpeller: string;

  constructor(
      searchClient: SearchClient,
      authHelper: AuthenticationHelper,
      openaiClient: AsyncOpenAI,
      chatgptModel: string,
      chatgptDeployment: string | null,
      embeddingModel: string,
      embeddingDeployment: string | null,
      sourcepageField: string,
      contentField: string,
      queryLanguage: string,
      querySpeller: string
  ) {
      super();
      this.searchClient = searchClient;
      this.chatgptDeployment = chatgptDeployment;
      this.openaiClient = openaiClient;
      this.authHelper = authHelper;
      this.chatgptModel = chatgptModel;
      this.embeddingModel = embeddingModel;
      this.chatgptDeployment = chatgptDeployment;
      this.embeddingDeployment = embeddingDeployment;
      this.sourcepageField = sourcepageField;
      this.contentField = contentField;
      this.queryLanguage = queryLanguage;
      this.querySpeller = querySpeller;
  }

  async run(
    messages: Array<{ [key: string]: any }>, 
    stream: boolean = false, 
    sessionState: any = null, 
    context: { [key: string]: any } = {}
): Promise<{ [key: string]: any }> {
    const q = messages[messages.length - 1]["content"];
    const overrides = context["overrides"] || {};
    const authClaims = context["auth_claims"] || {};
    const hasText = ["text", "hybrid", null].includes(overrides["retrieval_mode"]);
    const hasVector = ["vectors", "hybrid", null].includes(overrides["retrieval_mode"]);
    const useSemanticRanker = overrides["semantic_ranker"] && hasText;
    const useSemanticCaptions = overrides["semantic_captions"] && hasText ? true : false;
    const top = overrides["top"] || 3;
    const filter = this.buildFilter(overrides, authClaims);
    let vectors: Array<any> = [];
    if (hasVector) {
        vectors.push(await this.computeTextEmbedding(q));
    }
    const queryText = hasText ? q : null;
    const results = await this.search(top, queryText, filter, vectors, useSemanticRanker, useSemanticCaptions);
    let userContent = [q];
    const template = overrides["prompt_template"] || this.systemChatTemplate;
    const model = this.chatgptModel;
    const messageBuilder = new MessageBuilder(template, model);
    const sourcesContent = this.getSourcesContent(results, useSemanticCaptions, false);
    const content = sourcesContent.join("\n");
    userContent = [q + "\n" + "Sources:\n " + content];
    messageBuilder.insertMessage("user", userContent);
    messageBuilder.insertMessage("assistant", this.answer);
    messageBuilder.insertMessage("user", this.question);
    let chatCompletion = await this.openaiClient.chat.completions.create({
        model: this.chatgptDeployment ? this.chatgptDeployment : this.chatgptModel,
        messages: messageBuilder.messages,
        temperature: overrides["temperature"] || 0.3,
        max_tokens: 1024,
        n: 1,
    });
    chatCompletion = chatCompletion.modelDump();
    const dataPoints = { "text": sourcesContent };
    const extraInfo = {
        "data_points": dataPoints,
        "thoughts": [
            new ThoughtStep("Search Query", queryText, { "use_semantic_captions": useSemanticCaptions }),
            new ThoughtStep("Results", results.map(result => result.serializeForResults())),
            new ThoughtStep("Prompt", messageBuilder.messages.map(message => message.toString())),
        ],
    };
    chatCompletion["choices"][0]["context"] = extraInfo;
    chatCompletion["choices"][0]["session_state"] = sessionState;
    return chatCompletion;
}
}